{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06493bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_in_years: 0.82624\n",
      "sex: 0.08918\n",
      "episode_number: 0.00859\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# setting base directory (folder where your notebook is located)\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "\n",
    "model_path = os.path.join(BASE_DIR, \"models\", \"lr.pkl\")\n",
    "data_train_path = os.path.join(BASE_DIR, \"data\", \"processed\", \"sepsis_train.csv\")\n",
    "data_test_path  = os.path.join(BASE_DIR, \"data\", \"processed\", \"sepsis_test.csv\")\n",
    "\n",
    "# print(\"Model path:\", model_path)\n",
    "# print(\"Train data path:\", data_train_path)\n",
    "# print(\"Test data path:\", data_test_path)\n",
    "\n",
    "# loading model\n",
    "raw_model = joblib.load(model_path)\n",
    "\n",
    "# handling RandomizedSearchCV or plain pipeline\n",
    "if hasattr(raw_model, \"best_estimator_\"):\n",
    "    model_best = raw_model.best_estimator_\n",
    "else:\n",
    "    model_best = raw_model\n",
    "\n",
    "# extracting preprocessor and classifier\n",
    "\n",
    "preprocessor = model_best.named_steps[\"columntransformer\"]\n",
    "clf = model_best.named_steps[\"logisticregression\"]\n",
    "\n",
    "# loading & splitting data\n",
    "\n",
    "sepsis_train = pd.read_csv(data_train_path)\n",
    "sepsis_test = pd.read_csv(data_test_path)\n",
    "\n",
    "X_train = sepsis_train.drop(columns=[\"hospital_outcome\"])\n",
    "y_train = sepsis_train[\"hospital_outcome\"]\n",
    "\n",
    "X_test = sepsis_test.drop(columns=[\"hospital_outcome\"])\n",
    "y_test = sepsis_test[\"hospital_outcome\"]\n",
    "\n",
    "# transforming data using same preprocessing as training\n",
    "\n",
    "X_train_t = preprocessor.transform(X_train)\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "# converting sparse matrices to dense if needed\n",
    "if hasattr(X_train_t, \"toarray\"):\n",
    "    X_train_t = X_train_t.toarray()\n",
    "    X_test_t = X_test_t.toarray()\n",
    "\n",
    "# creating SHAP linear explainer\n",
    "\n",
    "explainer = shap.LinearExplainer(clf, X_train_t)\n",
    "shap_values = explainer.shap_values(X_test_t)\n",
    "\n",
    "#print(\"SHAP values shape:\", np.array(shap_values).shape)\n",
    "\n",
    "# computing SHAP feature importances\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# getting names of transformed features\n",
    "raw_feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# renaming sex_1 to sex and cleaning transformer prefixes\n",
    "clean_feature_names = []\n",
    "for name in raw_feature_names:\n",
    "    clean = (\n",
    "        name.replace(\"onehotencoder__\", \"\")\n",
    "            .replace(\"standardscaler__\", \"\")\n",
    "    )\n",
    "    # renaming sex_1\n",
    "    if clean == \"sex_1\":\n",
    "        clean_feature_names.append(\"sex\")\n",
    "    else:\n",
    "        clean_feature_names.append(clean)\n",
    "\n",
    "# combining names with SHAP values\n",
    "feature_importance = list(zip(clean_feature_names, mean_abs_shap))\n",
    "\n",
    "# sorting features by importance\n",
    "sorted_feature_importance = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# printing results\n",
    "print(\"Mean absolute SHAP values are shown below & higher values indicate higher feature importance.\\n\")\n",
    "\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe983e3c",
   "metadata": {},
   "source": [
    "SHAP Explanation and Feature Importance\n",
    "\n",
    "- SHAP (SHapley Additive exPlanations) is a method used to explain how individual features contribute to a machine learning model’s predictions. It assigns a numerical value to each feature that represents how much that feature pushes the prediction up or down. A higher SHAP value indicates a higher level of importance, meaning the feature has a stronger influence on the model's decision. SHAP is particularly useful for understanding both global feature importance and how a single observation is being predicted. In this analysis, SHAP values are used to determine which features are most important in the logistic regression model predicting sepsis hospital survival.  \n",
    "\n",
    "- To interpret the logistic regression model, SHAP values were computed to measure the contribution of each feature to the model’s output. The model includes three predictors: age_in_years, sex, and episode_number. The SHAP values represent the average magnitude by which each feature affects the prediction across all test samples.  \n",
    "\n",
    "- The results show that age_in_years is the most important feature, with a mean SHAP value of 0.82624. This clearly indicates that age has the strongest overall influence on the model’s predictions. The feature sex has a mean SHAP value of 0.08918, but this value is relatively small compared to age, suggesting that sex does not meaningfully influence the model’s output. The smallest SHAP value is associated with episode_number, at 0.00859, showing that this feature has almost no effect on the predictions and is effectively ignored by the model.  \n",
    "\n",
    "- Overall, the SHAP analysis shows that age_in_years is the dominant predictor used by the model, sex has minimal influence, and episode_number contributes almost nothing to the final prediction. This provides a clear understanding of which features drive the model and confirms that age is the primary factor in predicting sepsis survival outcomes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a4c64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
